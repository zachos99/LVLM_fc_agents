<doc sitename="Notes on Deepseek v3: Is it truly better than GPT-4o and 3.5 Sonnet?" title="Notes on Deepseek v3: Is it truly better than GPT-4o and 3.5 Sonnet?" date="2025-06-04" fingerprint="2673d16c3d0aca5a">
  <main>
    <graphic src="https://styles.redditmedia.com/t5_81eyvm/styles/communityIcon_cumnsvx9kzma1.png?width=96&amp;height=96&amp;frame=1&amp;auto=webp&amp;crop=96:96,smart&amp;s=d46f10b1590944719984c2187874fbd75260d22c" alt="r/LocalLLaMA icon"/>
    <p>Subreddit to discuss Llama, the large language model created by Meta AI.</p>
    <head rend="h1">Notes on Deepseek v3: Is it truly better than GPT-4o and 3.5 Sonnet?</head>
    <p>After almost two years of GPT-4, we finally have an open model on par with it and Claude 3.5 Sonnet. And that too at a fraction of their cost.</p>
    <p>There’s a lot of hype around it right now, and quite rightly so. But I wanted to know if Deepseek v3 is actually that impressive.</p>
    <p>I tested the model on my personal question set to benchmark its performance across Reasoning, Math, Coding, and Writing.</p>
    <p>Here’s what I found out:</p>
    <list rend="ul">
      <item>
        <p>For reasoning and math problems, Deepseek v3 performs better than GPT-4o and Claude 3.5 Sonnet.</p>
      </item>
      <item>
        <p>For coding, Claude is unmatched. Only o1 stands a chance against it.</p>
      </item>
      <item>
        <p>Claude is better again for writing, but I noticed that Deepseek’s response pattern, even words, is sometimes eerily similar to GPT-4o. I shared an example in my blog post.</p>
      </item>
    </list>
    <p>Deepseek probably trained the model on GPT-4o-generated data. You can even feel how it apes the GPT-4o style of talking.</p>
    <head rend="h1">Who should use Deepseek v3?</head>
    <list rend="ul">
      <item>
        <p>If you used GPT-4o, you can safely switch; it’s the same thing at a much lower cost. Sometimes even better.</p>
      </item>
      <item>
        <p>v3 is the most ideal model for building AI apps. It is super cheap compared to other models, considering the performance.</p>
      </item>
      <item>
        <p>For daily driving, I would still prefer the Claude 3.5 Sonnet.</p>
      </item>
    </list>
    <p>For full analysis and my notes on Deepseek v3, do check out the blog post: Notes on Deepseek v3</p>
    <p>What are your experiences with the new Deepseek v3? Did you find the model useful for your use cases?</p>
    <graphic src="https://preview.redd.it/ve5phs3ljtne1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8c4746d7e176520ff48a8357204e714131d3fc62" alt="reMarkable Paper Pro"/>
    <graphic src="https://preview.redd.it/gkjawlgljtne1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2a1c7b4454295a7608ee25b60df156ed391d77c2" alt="The ultimate paper tablet"/>
    <graphic src="https://preview.redd.it/ytexzwtljtne1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8f0249732702445cf66ec58350ed28bb25b4c87c" alt="Closer to paper than ever"/>
    <graphic src="https://preview.redd.it/5v7mrz6mjtne1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5a2dc26195504247bd323d94849e7618db8e536b" alt="Distraction-free by design"/>
    <graphic src="https://preview.redd.it/wwjs3tkmjtne1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6ac2cefd78b7c70ce6f5edc291e0245e98fd8eaa" alt="Lightweight and portable"/>
  </main>
  <comments><p>I've tried it out extensively. For me, it's not as good as 3.5 Sonnet on coding, but it is so cheap that it is a good replacement for gpt4o that I used for simpler tasks that are not privacy-sensitive.</p><p>I do think Google's free Gemini models on AIstudios are good enough for this purpose as well though, so I don't actually find myself using Deepseek a lot currently. But if Google puts them behind a paywall, then deepseek it is.</p><p>True it can replace anything gpt 4o is used for. I found Sonnet to be overall better as well for day to day tasks.</p><p>I’d like to know Anthropic’s secret. Sonnet is the most enjoyable model to work with.</p><p>Total speculation, but I'd imagine it's by building on Chris Olah's interpretability research. If you listen to the one-and-only podcast interview he did in between his time at OpenAI and before Anthropic was really going, you get a sense of how much care and empiricism they're probably bringing toward understanding and steering model behavior:</p><p>https://80000hours.org/podcast/episodes/chris-olah-interpretability-research/</p><p>You can also look at what GoodfireAI is building on top of his (and other's) research to see the impact of feature steering:</p><p>https://xcancel.com/GoodfireAI/status/1836077966515921011</p><p>Thanks for the link!</p><p>True, it has the personality of a true LLM. It feels like the tone of LLMs when you don't force them to behave a certain way; for example, GPTs feel more corporate-y.</p><p>Really. A model almost one year old still beats everything in code, it’s truly incredible</p><p>They did update it not that long ago, but yeah it’s still incredible. Wish they’d release a new Opus</p><p>Can you do university assignments using these programs? Is Chat Gpt the best?</p><p>Lol fuck off</p><p>Why? I was asking a question</p><p>I would have a different opinion on Sonnet....you can feed hundreds of lines of code to ChatGPT O1 and it can send it back...while on Claude, you would hit rate limits quick. Get annoying</p><p>I haven’t had that problem with the API, but yeah with the app the rate limits are awful and I canceled awhile back.</p><p>Can you use these programs to do university work?</p><p>yes, you can</p><p>Thank you very much! ChatGPT free model runs out so have to wait 3 hours.Any way to get round this? Any other AI programs like ChatGPT?</p><p>just use claude, or deepseek. There is gemini too</p><p>Comment removed by moderator</p><p>Check Deepseek r1 or OpenAI o1 pro if budget allows.</p><p>28 days later here I come hehe</p><p>So what I wanted to ask is how v3 is supposed to replace 4o coz I use 4o as a model that has real time data. Some analysis of the ongoing events and such. And I've decided to do so with V3 and it doesn't go like that because its database is limited to 2023. Because of that I find v3 as 4o mini on steroids and only as good as that.</p><p>So my question is: Am I using v3 kinda wrong? Do I need to tap search in the chat when I want v3 to check real time data? But if so 4o doesn't always go on the web when I ask something. Only when it thinks that its data mind needs refreshement(like the news that came out today or so)</p><p>Yeah, for web search you have to enable the web icon on the Deepseek chat for real time data. 4o basically determines if it needs to search for a particular question by itself. So, if it feels like it will search.</p><p>Thanks! I've tried but that feature doesn't work today so I've decided to take a look and as I see to ask stupid questions :) ..thanks again have a nice day!</p><p>They are overloaded, and didn't work for me as well. Ah, it's fine. Have a good day.</p><p>I have a code problem and exhausted claude limit on paid and it still couldnt solve it. And deepseek solved on first try. I think claude quality seems worse recently</p><p>OpenRouter to remove Claude limits.</p><p>Or just use the Claude API through their own workbench, which doesn't require paying overhead to use an intermediate service.</p><p>https://console.anthropic.com/workbench</p><p>I use Cline which uses Claude API. First via Anthropic as you suggest but I’ve experienced daily limit cutoffs. OpenRouter doesn’t suffer those limits.</p><p>I don’t believe their pricing is higher than Anthropic but I can’t say for sure. It keeps me working which is the most important thing.</p><p>What do you mean "don't believe". How do you think the service works?</p><p>They do take a commission for being a router. And they explicitly say how much</p><p>Replace “I don’t believe” with “to my knowledge”</p><p>I also stated “but I can’t say for sure.”</p><p>I was specifically addressing the API limits in my reply.</p><p>It looks like there is a 5% flat fee per deposit with token charges being the same as the API. But open router doesn’t charge tax so still potentially cheaper.</p><p>Again, pretty moot since my point was addressing API limits.</p><p>Perplexity:</p><p>OpenRouter charges a 5% fee plus $0.35 per deposit on top of the base model prices14. While OpenRouter provides the same per-token pricing as accessing models directly through providers like Anthropic, this additional loading charge makes it slightly more expensive than calling the APIs directly4. Additionally, OpenRouter doesn’t charge taxes, unlike using the Claude API directly, which can make it more cost-effective in some cases3.</p><p>Yeah, I also do that often. There is some variance to it, so trying with different models is a good strategy.</p><p>I haven't noticed a decline recently myself, but that may be since I only use Anthropic's API, rather than their subscription.</p><p>Damn shame that the API logs and trains on data. Kind of wild. Even the non-paid versions of GPT and Claude let you turn that off.</p><p>EU version of AIstudios supposedly doesn't, according to their ToS. But yeah, you probably don't want to put sensitive material in there if you're not in one of the excluded countries.</p><p>Where are you seeing excluded countries? I just read their entire privacy policy.</p><p>https://ai.google.dev/gemini-api/terms</p><p>Oh, I was talking about Deepseek.</p><p>Which gemini models? How can i access them</p><p>Comment removed by moderator</p><p>second it being useless of c++. The way it currently outputs looks like using github to copy code and then as you are changing some lines of code, you decide that you're bored and just vomit all over the code.</p><p>hmm, no. I did not find them useless for C and C++. In fact even Qwen 2.5 7b was not useless. Deepseek converted loops in C code to avx for me no problems.</p><p>I have noticed they are quite good at converting normal code to SIMD as well, but when you have to be careful around memory alignment they will very confidently write bugs where you're reading/writing past the end of allocated memory or invoking undefined behavior, and then you have a bug that takes hours to fix</p><p>yes true.</p><p>I have had a similar experience, even going back two years. It might not be the greatest but it is more than adequate especially if you are already working in a clean, functional style.</p><p>I've had reasonable success with C# WPF on Claude. But I was just building general applications with UI and local mongo DB integration. I imagine it works really well building back-end logic with .NET, SQL and MVC if you wanted to go the web dev stack route.</p><p>What are your main complaints with Claude in regards to C#?</p><p>Comment removed by moderator</p><p>Cool, I just went down the avalonia rabbit hole. Sounds really interesting! Although I'm primarily a MS user I have been entertaining the idea of cross platform development through react native/iOS. Avalonia sounds cool! But it seems like it is still a bit too niche for these LLMs.</p><p>That's neat. Thanks for the addition. Have you found Gemini 2.0 or o1 to be good for c and c++?</p><p>Gemini is great with C and C++. I imagine because Google is largely a C and C++ shop internally. They have the motivation to have it do a good job. Gemini is also very good at recommending performance improvements in systems level code as well.</p><p>I have found sonnet being good for c++ when you ask small spesific things or questions about implementation and patterns.</p><p>For example "This is my current class: ... What is the best way to implement X."</p><p>Sonnet is ok with Rust. It sometimes forgets about borrowing, but that's usually a simple fix. I've mostly used it for one off functions though. I will say that the qwen 2.5 3b model over been using for type hints works pretty good in Rust as well.</p><p>C and C++ are high level languages</p><p>Lol k, gatekeeping low level languages to assembly huh? Wild</p><p>Specifically for C/C++, I found chatgpt, gemini and claude to be not upto the mark. When I uploaded an API document and asked to write c code for server, they always miss one or the other API. Specifically chatgpt 4o misses a lot of things. Sometimes even didn't finish writing code and was stopping. Due to this there was always daily limit exhaustion without completing full code. Its very annoying experience.</p><p>But yesterday I just wanted to try deepseek v3 after hearing a lot of buzz. With the first prompt itself, it wrote almost all code without missing APIs and followed almost all details from uploaded document. With few more prompts it gave me what I could get from chatgpt after 4-5 days (that also with lot of efforts and frustration). I am going to try deepseek v3 regularly and test the consistency.</p><p>Comment removed by moderator</p><p>You're not supposed to trust it, you're supposed to vet it. It's the same as having a junior dev at your disposal, except it gets done immediately what takes them days / hours. Doesn't give you any less excuse to review it like you would a junior devs code, wtf is with this mentality? The point is it shits out the 90% solution in 3 minutes of promts. Sure you have to spend 45 minutes vetting it and an hour completing the rest of it but it was gonna take you 3 hours. You're acting like you want the solution instantly and to check it in with no review. Lmao</p><p>My thoughts on Deepseek V3:</p><p>1: CHEAP. I used it all day, I spent 7 cents. I'd have had a substantial bill with Claude or OpenAI for that much usage. Their it-just-works prompt caching really helps.</p><p>2: It's not as good as Claude Sonnet 3.5 or o1/o1 pro at coding, but, it's GOOD at coding. When claude/openAI have an issue with something, it's a good 2nd or 3rd option for trying to solve the problem, and I've had some success with it. Sometimes it has solutions the other AI missed, but usually it feels like it's more-or-less giving me exactly what GPT4o would have...</p><p>3: It's awful at long form writing. Flat-out. Repetitive, stupid, and prone to looping. I could NOT find a setting that avoided this. It makes a lot of stupid mistakes. It's not as noticeable if you're writing a page or two, but once you start pushing a narrative out to chapter or novel length, you start seeing all kinds of issues. Trying to adjust presence penalty and rep pen has such a ferocious effect that words end up becoming complex and ridiculous as the text continues. It's just bad all round. I'd write with a 9b gemma tune before I'd fire this thing up for fiction.</p><p>4: It's great as a cheap-as-chips intelligence for managing an agentic workflow. The generous prompt cache (sticking around for HOURS after you use it) means you can really hammer down on an agent workflow with this thing and barely spend a dime.</p><p>For anything EXCEPT writing, I'd use it over GPT 4o, but there are definitely better models out there to use if you've got the cash/interest. That said, it's stunningly cheap and impressively well done for what it is.</p><p>I can't get it to not repeat itself far too quickly in fiction writing.</p><p>It's brilliant up to that point, probably 8k tokens in, then rip.</p><p>Fudged with all the settings there are, including DRY, no luck.</p><p>Yeah, same issue here. It's mostly great, it's smart and characters sometimes make insightful leaps of reasoning in complex situations. But if you don't provide a new topic or shake things up, characters just go back and forth repeating the same two lines of dialogue. And once a phrase ends up in the context, they keep coming back to it, sometimes thousands of tokens later.</p><p>How did you experiment with DRY? I didn't think any hosting services implemented it. Unless you're running it locally?</p><p>Openrouter offers it. Really wish they'd implement XTC though, can only get that locally as there's only so many APIs I'm willing to throw money at.</p><p>Dry really screws me up on long contexts. I had to start limiting it to 2048 locally. Characters start to alliterate and stop making sense. I know it's dry because I turn it down/off and the issue goes away. Worse on qwen than llama, at least in tabbyapi.</p><p>XTC can switch things too much. Characters with an icon next to their name begin to randomize it after 3 messages. Also affects other formatting.</p><p>I find surprisingly, Chinese LLM better at English Language creative writing than American. Sonnet was too intllectual for a fairy tale, Gemini too bland. Qwen 2.5 72 and DeepSeek were exactly what I wanted.</p><p>Frustrately，Chinese LLM no good at Chinese Language 😢</p><p>Less alignment.</p><p>probably.</p><p>For qwen do you use a finetune? Qwen is at a good size that indie finetuners have done a lot of work on them, I feel kinda pessimistic about DeepSeek getting the same treatment, but it desperately needs it. The base model is so fantastic but the instruct is like... has some issues that i think should be easy to fix but ATM the post-training is not as advanced as claude.</p><p>no, just vanilla 72 instruct. my point was is not deepseek genarally better at prose, but that everyone has their own tastes. I've seen finetune outputs, they all have neckbearded flamboyant roleplay/fantasy style; I much more prefer drier prose.</p><p>Sonnett's very good at instruction following. If you don't like the creative output you could almost certainly get what you want by testing different prompts.</p><p>yeah I've wrestled a bit, still was not what I wanted.</p><p>You didn't use DRY actually unless you run deepseek locally</p><p>So it's fake?! OPENROUTER LIED TO ME AND LET ME PUT FAKE NUMBERS INTO THE API CONTROLLER!?!?!</p><p>Wtf you on about, DRY isn't in their docs, DeepSeek's docs, or any provider's docs, since DRY is a local thing. Less about OpenRouter lying, more that their API doesn't return any message telling you something isn't supported. If you expand the provider on the model's page on OR, it shows you the provider's supported parameters. Same for using OR's parameters API. Thinking that DRY is supported is entirely user or frontend dev error.</p><p>No they don't, and they can't "offer" anything the provider doesn't. OR is just the middleman; OR does not host anything.</p><p>One complaint I have is OR doesn't show us whether</p><code>prompt</code>(text completion) is supported. We would have to check the provider's docs and/or check if the response is correct.<p>Interestingly, recently we found out text completion works on DeepSeek's API, undocumented. Their docs for FIM (fill in the middle) tells us to use</p><code>prompt</code>and<code>suffix</code>where prompt is the text before the middle and suffix is the text after the middle. However, it is possible to send<code>prompt</code>only, with FIM sequences:<code>&lt;｜fim▁begin｜&gt;{prefix}&lt;｜fim▁hole｜&gt;{suffix}&lt;｜fim▁end｜&gt;</code>. OR originally didn't transmit raw<code>prompt</code>to DeepSeek when they released, but after some feedback, does.<p>___</p><p>Temp 1.8, Frequency Penalty .15, Top-P .98. DeepSeek V3 has a bad "bug" where it breaks and becomes garbled at some point after 500 tokens of output, so you have to generate in smaller sections. Overall not so good at trying to continue large bodies of text without frequent intervention. As an RP chat user, unfortunately it still has some repetition issues unless you put in more effort and guide how it will act next to distract it from what it would generate on its own, but at that point you wouldn't be "chatting" with it and more like using it as a tool to produce your ideas.</p><p>shakes fist at ST interface</p><p>Well, that explains why DRY works so much better when I'm running off Tabby and not OpenRouter.</p><p>Your samplers menu might be borked.</p><p>What if you use the API in sillytavren and increase the repeition penalty?</p><p>I cranked it up pretty high, no help.</p><p>Honestly, even cranking up temperature, which almost every model is very sensitive to, has little effect on Deepseek. With Llama 405, 1.05 will start to give weird results. With Deepseek, 1.75 works fine, you have to push it even higher to consistently get trash. But it feels like there is no window of creativity. Either every response is a repetition and the same deterministic response as the last, or it's just random garbage.</p><p>I feel like it is very heavily oriented toward specific outputs, with logic and creativity both in the backseat.</p><p>I didn't believe the hype but it helped me more than Claude today on something hard with c#. It's possible I gave it clearer context based on my fails with Claude. They are both quite capable cosers regardless. I'll be rotating back and forth.</p><p>I’ve tried them for building html and react. What I’ve found is that deepseek and other open source models often generate results that are not polished. Claude and Gemini exp can generate more visually appealing webpages. I doubt these open weight models haven’t undergone a careful post training process to enhance such capability. However I believe since the fundamental capabilities shown by the benchmarks are strong, the further finetuned version can catch up with the closed weights models.</p><p>There's so much they can do with such limitations. Fine-tuning such a model will be a task as well, let's see who cracks it.</p><p>Well, their website is free and their API is cheap.</p><p>In my experience it’s better than 4o and close to Sonnet, you just might need more than one prompt to get what you want.</p><p>On their website you have access to R1-Lite and a search feature. Their search feature is better than 4o. It’s not as good as Gemini Deep Research.</p><p>Yeah, it gets a boost in reasoning with the deep think, though it's not refined and sometimes gets into a thought loop.</p><p>It’s cool switching between the two.</p><p>I can’t wait to see full R1. In my experience, QwQ gets stuck in loops more often, but I occasionally see it with R1 too.</p><p>I think you made a mistake in your testing caused by wrong assumption.</p><p>“You can enable this feature in the Deepseek chat. Though it’s not as good as o1, it still improves the reasoning abilities of the LLM to some extent."</p><p>Later, you test V3 with Deep Think feature.</p><p>More likely then not, when enabling Deep Think, you're defaulting back to Deepseek R1 model and not V3. There's no indication that I've seen that V3 has a thought chain and I think the distillation meant finetuning in final answers that R1 gives for reasoning, without finetuning on the full reasoning chain, though we can go back to the tech report and refresh our knowledge on this. So, I think you've tested R1 and V3 assuming it's one model.</p><p>Isn't Deep Think simply a toggle to use R1-Lite-Preview, which has nothing to do with V3 at all?</p><p>That's what I'm trying to say, yes.</p><p>Comment deleted by user</p><p>No, you're right; it's better than GPT-4o.</p><p>It is indeed good. It's results are like early chatgpt days–so good results!</p><p>Yes, there's actually no use of GPT-4o. It's time for an update.</p><p>I’ve been liking it better for coding, i am doing a lot of Linux interfacing and it seems its knowledge set is possibly more current.</p><p>yes, knowledge of avx512 was nice.</p><p>I couldn't get deepseek v3 to create a nice react website from scratch where as other AIs were able to do it quite well (o1 mini and opus/sonnet) but I didn't experiment a lot with it so keep that in mind. I am open to ideas to get deepseek v3 work.</p><p>But it did quite well on working/fixing codes that the other AIs wrote.</p><p>I think deepseek isn't as good as Claude 3.5 if talking about coding. Claude is still betting in those area.</p><p>Any idea why Deepseek-v3 is not available in Groq</p><p>that's what I'm wondering. deepseek + groq would be insane. maybe groq has a deal with llama?</p><p>Wrong prompt. Watch this.</p><p>The whole thing is a big fat lie coming from China. No body trusts them or their claims. COVID wouldn't have killed millions if they were open and honest. Why are you trying to justify these morons. Are you associated with them?</p><p>The point was only to show how rudimentary this "Sorry, that's beyond my current scope." censorship is – it essentially just looks for certain keywords ("Xi Jinping", "Tiananmen Square" etc.) and artificially removes the message. You can see in its thought process how it lays everything down that has to do with how China is not a democratic state, though given that no "sensitive" names are mentioned the AI is not stopped.</p><p>Now, whatever material the AI was trained on specifically, and whether that material is or is not propaganda, is another matter. What I was trying to point at is just that in what it outputs, based on what it knows, it's very poorly regulated.</p><p>Of course it won't tell the real thing if the source data itself is propaganda. A real human wouldn't do that if all the information it's been exposed to is propaganda. The equivalent here is a human saying something else than what it knows or refraining from saying something that it knows to not upset some authorities. That's what I cared about when talking about AI censorship in this thread, and DeepSeek is barely censored in this way.</p><p>I have no reason and interest in endorsing the information itself that DeepSeek outputs or affirming whether the information that DeepSeek is allowed to output is true or not, and am not in any way associated with any entity linked to this project or to any sort of political power. This subject is beyond the scope of what I wanted to express. What I wanted to express is that DeepSeek is allowed to output a lot of shit, and for the forbidden things there are very rudimentary guardrails put in place.</p><p>Thanks for your time and effort to make this post. Helpful !</p><p>Glad you liked.</p><p>for me, it fits in the middle between Gemini 2.0 and Sonnet, it still makes mistakes and gets confused too for even simple instructions, but it is fast and much cheaper. so again, very acceptable model.</p><p>Every current model is better than gt4o ...</p><p>I've begun the task of quantizing Deepseek V3 to INT4 and loading on constrained RAM (4GB currently in testing).</p><p>Last night ran numerous tests, loaded 61 layers, accessed all model weights files, tested all 256 experts in MoE.</p><p>Today I hope to complete first Inference.</p><p>Then I'll begin optimizations.</p><p>This will allow Deepseek V3 685B model to run on constrained RAM or VRAM, such as an Nvidia 3060.</p><p>Once complete, I'll do the same for other LLM variants like Llama 3 405B, Llama 3.3, Qwen2.5, QwQ, etc.</p><p>I think this is sci-fi novel</p><p>Tbh I enjoy Deepseek a lot, but I’m a bit worried on where my data goes, so I do not do any work-related tasks that may have any sensitive information on it</p><p>I'm on the fence about it because of the possibility it might share my code with the Chinese government or other parties</p><p>I doubt that anything I do or say is the least bit interesting to the Chinese government. But trying Deepseek did sort of give me the same feeling I get from reading an email from an unknown source offering me a loan. Something felt a bit off but it's probably just my own paranoia or even prejudice. In any case I'm also on the fence for a while.</p><p>Deepseek is definitely heavily trained on gpt-4o responses. If you give it a general assistant system prompt and ask it what model it is, it'll tell you it's gpt-4o sometimes</p><p>Can someone figure out what all these accounts have in common?</p><p>They can't all be hacked accounts?</p><p>Is there some sort of commission or kickback structure going on?</p><p>It's bizarre.</p><p>It's a good model, and there's no commission.</p><p>Why is everyone so desperate to share their 'amazing' findings in the same, inane, format?</p><p>The common thread is that Deepseek is amazing bro.</p><p>It's not that amazing. We had plenty of cheap LLMs via API. If you want to run it locally then fine, but that's not viable for most people with this model.</p><p>It's that and that it's SOTA.</p><p>It's 900 bajillion params, bro.</p><p>This is local Llama. We don't need any more pontification and spam about some third party api.</p><p>I applaud that anyone could run it locally but WHO is running it locally?</p><p>Where are THOSE posts?</p><p>Yeah you have a point, but also gotta understand that a lot (not all, but a lot) of the distaste about API is about price and how poor people won't be able to effectively access AI. In this case the price is quite literally lower than buying the hardware so it's quite nice from that perspective.</p><p>There are a lot of threads about running it locally: https://old.reddit.com/r/LocalLLaMA/comments/1hne97k/running_deepseekv3_on_m4_mac_mini_ai_cluster_671b/</p><p>But again the hardware price is higher than the API. Knowing that it's available on local and will get optimized down to be easier to run in the future, and meanwhile the present day API is very affordable, makes me feel very good and excited about Deepseek.</p><p>Well, I recently built an Epyc 7713 workstation. Initially I wanted to be future proof with its 7 PCIe x16 slots (multi GPU inferencing) but now that I’d need like 400 GB VRAM for this model, I’m gonna try upgrading the RAM and try to run it on the CPU. If my tests and calculations are correct, I will get 1.5 to 2 token per second, which is fine for tasks that require 100% privacy. I can always switch back to an API for less sensitive tasks.</p><p>...or you could just use Qwen.</p><p>people are excited about a new capable model that costs way less.</p><p>everything popular isn't because of some conspiracy</p><p>Sooooo it means model trained on model is better? Would that be oversimplifying? Also is this legal?</p><p>What type of things are you coding?</p><p>Are there any frameworks for CoT or increase thinking time when using OpenRouter API?</p><p>And I thought I was the only one who did not find DS3 match up to Sonnet - such is the hype here sometimes! I mean its not too bad though. I was actually getting used to the online search feature on their chat site to ask the model to update its knowledge before answering, but DS3 is just so stubborn..</p><p>Is it actually better than Qwen?</p><p>I don't really get the hype for me. Deepseek changes to Chinese halfway through the response sometimes. Seems kind of useless unless you are completely bilingual.</p><p>I used deepseek and GPT at reasoning, analysis and reading vague things between the lines. V3 was as good as GPT for me with more or less similar results. But Sonnet was just better. It answers questions or lists things in one go, the rest needs some confirmation or additional info or sometimes don't get it. It's expensive with its limits, but faster to get to the point.</p><p>best way to utilize deep seek v3?</p><p>Is anyone else hosting this model yet? I read the privacy policy and…didn’t like it.</p><p>Does DeepSeek v3 API use the 'DeepThink' feature by default?</p><p>You need to enable it using a button on the web UI.</p><p>Deepseek v3 is cheaper than GPT4-o but seems similar to same price as GPT4o-mini?</p><p>|| || |Input Cost|$0.15 per million tokens [GPt 4o-mini]|$0.14 per million tokens [Deepseek v3]|</p><p>on some maths problems, yes that is what I witnessed</p><p>Can I use Deepseek for rust?</p><p>Recent AI bill has gone up quite a bit so considering switching from 4o to DeepSeek. Anyone has experience doing it?</p><p>As a lawyer and extensive user of chatgpt plus. I can confirm that in my field, DeepSeek already performs better. It is accurate in terms of the latest clauses in the statute/act. Not to mentioned that it is free and can read a very lengthy documents, agreements and statutes. Mind-blown.</p><p>good to know. gpt struggles with long documents and hallucinates frequently with poor referencing. how are you finding deepseek comparitively?</p><p>personally, i think DeepSeek 100x better than GPT Plus. it is a literal AI lawyer. For example, u can make it read a Land Law Act (eg : 200 pages) and then you can ask question on it. DeepSeek can come up with precise legal advice and quote exact sections from the Land Law Act. Most human lawyer will take about few hours or days to do the same task.</p><p>what is better than R</p><p>https://github.com/deepseek-ai/DeepSeek-R1 Benchmarks and info here.</p><p>Had a niched use case with a specific prompt - gather context from a short sentence and return a json with specific key values.</p><p>deepseekv3 was doing so well. But it got DDOS-ed and i had to keep my services up so I swapped to gpt4o-mini. It was horrible. Then swapped to gpt4, its better but deepseekv3 was waaay better.</p><p>Note that gpt4 costs $2.50/M while deepseekv3 cost $0.14/M</p><p>If they could find a way to stabilize im never going back to OpenAI pricing lol</p><p>Although Gemini Advanced excels in several areas, ChatGPT, Copilot and Claude demonstrate great potential in specific tasks, such as forum searching and link summarization. Each of them offers features that make the user's life easier:</p><p>ChatGPT: Facilitates searching on forums by understanding informal language and providing accurate answers, as well as summarizing links quickly and efficiently.</p><p>Copilot: Uses artificial intelligence to analyze forum content and provide relevant answers, highlighting the ability to summarize YouTube videos.</p><p>Claude: Simplifies searching in forums with an intuitive interface and organization of results, in addition to offering customizable link summaries. It's important to note that the best tool will depend on your use case. Exploring the different options is essential to find the one that best suits your needs. Suggestion for the full post on Reddit: The evolution of AIs and the variety of options currently available are remarkable. I have been experimenting with different models, such as ChatGPT (paid version 4.0), DeepSeek and Gemini Advanced, and each has its own strengths. Gemini Advanced, with its wide range of models and gems, has stood out in my interactions. The ability to access up-to-date information and the context of 1 million tokens are key differentiators. Although I previously had difficulties accessing forums, Gemini Advanced has impressed me with its performance in tasks such as writing emails, organizing calendars and even interacting with WhatsApp. ChatGPT, Copilot and Claude: Highlight for forum search and link summary Although Gemini Advanced stands out in several areas, ChatGPT, Copilot and Claude demonstrate great potential in specific tasks, such as forum search and link summarization</p><p>It catched my attention that you said that Copilot has the ability to summarize Youtube videos. I think you may be undeserved.</p><p>Check out (https://cofyt.app). Youtube Summary, Highlights and Chat with transcript for detailed answers grounded in the video.</p><p>Copilot does have a desktop option copilot video summary</p><p>Thank you for sharing that with me. is there anything that you think copilot from msft is missing or is limited?</p><p>I personally think cofyt.app is a better AI experience specifically for long videos and getting detailed answers to your questions (grounded in the video). It´s also my personal preference to have a full screen experience, i´m not a fan of sidebars...</p><p>Here is the video you shared processed via COFYT t´s also great for translating content altough I could understand it perfectly. :)</p><p>https://www.cofyt.app/search/copilot-te-resume-los-videos-de-youtube-magicament-UUpc0BrXszuDhu2ZidGTI7</p><p>thanks</p><p>As a person who uses AI on a daily basis for everything from coding games to making pizza, I can confirm that deepseek is not very advanced when compared to gpt. Most ppl who don't barely use AI for anything are impressed by it. I don't understand the response to it</p><p>good question</p><p>Deepseek doesn't censor shit — its censorship is a bad (but good for me) joke. It just dumps its entire thought process or answer, which both contain all info one can dream of, and then it deletes it all and says "Sorry, can't say that". I can just screen record the answer. Because of this for me it's miles ahead of anything. Deepseek is also way more concise in its wording, it gives me way more concrete information, more real examples and usually also gives links. ChatGPT always beats around the bush and never answers what you actually want to know.</p><p>I've had a very interesting discussion with DeepSeek about building a decentralized music streaming platform, with a lot of follow-up questions on limitations, legal issues, censorship and ethics in general. What OpenAI's shitty soft-spoken, politically correct, corporate and government propaganda puppet would never even touch, DeepSeek gave it all. Of course, until the censorship kicked in and replaced it "Sorry, can't." Deepseek touched by itself on all the limitations of decentralization, blockchain, how it can be (and is) controlled by governments around the world, with countless real examples, including China (which it deleted afterwards, lol); ChatGPT would not do this, even with follow-up questions, and wouldn't dare even telling you how to circumvent government control, instead resorting to just tell you how to "work together with the regulations" or some shit. Here's a link to a DeepSeek "censorship" example: https://www.youtube.com/watch?v=QoInk2ZVxqk.</p><p>I've also plain asked it how to make a Molotov, and, while the response itself was a refusal, the thought process laid down every single fucking detail one would need to make it AND historical examples of usage.</p><p>Before this I wasn't hyped in any way about AI tech. I don't use it for coding, don't really feel any need to do so, and for searching stuff, validating knowledge and just bouncing off ideas, a censored, softened model with an agenda is no good. I'm not saying DeepSeek is truly objective — this also is dependent on the training data. But it has always given me clear, concise, on point answers, has determined my intent and interests well and has served them precisely.</p><p>In other words, it (mostly) gives answers to what I truly ask. Before I didn't even want to hear of LLMs; now I'm thinking of getting a computer on which I can run the model locally.</p><p>This is my experience with DeepSeek's "DeepThink (R1)" model through the DeepSeek's website. Apologies if this does not have much relation with the "v3" version you're talking about — I assume this trait is common to all DeepSeek models, and in this thread it doesn't seem to be talked about much. I don't have any other LLM experience outside of ChatGPT, so I can't say that there aren't other models which can do what DeepSeek does; I have a very narrow perspective. Your question is, though, whether DeepSeek is better than GPT, and for what I care, hell yes it is. If you care about this too then give it a try.</p><p>which one is best for learning concepts or researching?</p><p>Sonnet</p><p>GPUs are only needed for the AI traning or also for the daily operation?</p><p>bro like fr... i got annoyed with gpt so (i gave deepseek my info) by logging in lol, well anyways its crazy good, took me with gpt to make a stopwatch that works 20\100 times, and never amazingly, boom deepseek did it first try 💀 it literally made me perfect Update, and FixedUpdate similar to unity loops</p><p>Hay deepseek por paga</p><p>Deepseek got stupider not even 2 months later... great... now its worse than gpt even</p></comments>
</doc>